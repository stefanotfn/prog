{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanotfn/prog/blob/main/progettofinale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5hUhU_laWdH"
      },
      "source": [
        "# Cognition & Computation - Lab 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3Jgkp7KAcKl"
      },
      "outputs": [],
      "source": [
        "def _get_files_from_repo(files, repo):\n",
        "  repository_url = f\"https://raw.githubusercontent.com/flavio2018/{repo}/master/\"\n",
        "  for file in files:\n",
        "    ! wget -O {file} {repository_url}{file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJPbuuDSAth_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "files = [\"DBN.py\", \"RBM.py\"]\n",
        "_get_files_from_repo(files, \"Deep-Belief-Network-pytorch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilb0ecFRBUv8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as functional\n",
        "import torchvision as tv\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from DBN import DBN\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPnozyVxBFju"
      },
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLCyIIS4IyAX"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyoFQzR9BRDT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "mnist_train = tv.datasets.MNIST('data/', train=True, download=True,\n",
        "                                         transform=tv.transforms.Compose(\n",
        "                                                  [tv.transforms.ToTensor()]\n",
        "                                         ))\n",
        "\n",
        "mnist_test = tv.datasets.MNIST(\"data/\",\n",
        "                                train=False,\n",
        "                                download=True,\n",
        "                                transform=tv.transforms.Compose(\n",
        "                                        [tv.transforms.ToTensor()]\n",
        "                                ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C28fFlaABSws"
      },
      "outputs": [],
      "source": [
        "mnist_train.data = (mnist_train.data.type(torch.FloatTensor)/255)\n",
        "mnist_test.data = (mnist_test.data.type(torch.FloatTensor)/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2-EyqDgp50G"
      },
      "outputs": [],
      "source": [
        "mnist_train.data = mnist_train.data.to(device)\n",
        "mnist_test.data = mnist_test.data.to(device)\n",
        "mnist_train.targets = mnist_train.targets.to(device)\n",
        "mnist_test.targets = mnist_test.targets.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3mQDbPHBtQI"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build and train a DBN with the same architecture used in the previous Labs."
      ],
      "metadata": {
        "id": "kuXxOPPSlhnf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36EjxqUKB_J2"
      },
      "source": [
        "### DBN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBWXVpfkYI2Q"
      },
      "outputs": [],
      "source": [
        "dbn_mnist = DBN(visible_units=28*28,\n",
        "                hidden_units=[400, 500, 800],\n",
        "                k=1,\n",
        "                learning_rate=0.1,\n",
        "                learning_rate_decay=False,\n",
        "                initial_momentum=0.5,\n",
        "                final_momentum=0.9,\n",
        "                weight_decay=0.0001,\n",
        "                xavier_init=False,\n",
        "                increase_to_cd_k=False,\n",
        "                use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BfmZ39NYLTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773e1524-f0fd-4e1a-967e-727aec9473eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Training RBM layer 1\n",
            "|Epoch |avg_rec_err |std_rec_err  |mean_grad |std_grad  |\n",
            "|10    |1.1502     |0.0536       |246.5255   |7.1305     |\n",
            "|20    |1.0684     |0.0467       |227.6848   |6.6633     |\n",
            "|30    |1.0382     |0.0447       |221.2420   |6.0263     |\n",
            "|40    |1.0256     |0.0463       |217.0055   |6.5428     |\n",
            "|50    |1.0155     |0.0453       |213.8060   |6.0976     |\n",
            "--------------------\n",
            "Training RBM layer 2\n",
            "|Epoch |avg_rec_err |std_rec_err  |mean_grad |std_grad  |\n",
            "|10    |1.8542     |0.0670       |201.0035   |4.8348     |\n",
            "|20    |1.6475     |0.0585       |185.3583   |4.2873     |\n",
            "|30    |1.6086     |0.0547       |181.9974   |4.8947     |\n",
            "|40    |1.5950     |0.0547       |181.5495   |4.9507     |\n",
            "|50    |1.5836     |0.0545       |181.1162   |4.7372     |\n",
            "--------------------\n",
            "Training RBM layer 3\n",
            "|Epoch |avg_rec_err |std_rec_err  |mean_grad |std_grad  |\n",
            "|10    |1.1839     |0.0459       |232.2161   |5.8074     |\n",
            "|20    |1.0529     |0.0373       |208.5740   |4.8127     |\n",
            "|30    |1.0158     |0.0379       |203.1776   |4.8130     |\n",
            "|40    |0.9957     |0.0357       |200.4394   |4.9742     |\n",
            "|50    |0.9845     |0.0345       |199.3262   |5.1393     |\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 50\n",
        "batch_size = 125\n",
        "\n",
        "dbn_mnist.train_static(\n",
        "    mnist_train.data,\n",
        "    mnist_train.targets,\n",
        "    num_epochs,\n",
        "    batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu3kjq3MY2xz"
      },
      "source": [
        "### Readout classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "propriety of learned rappresentation esamination"
      ],
      "metadata": {
        "id": "ebvojdCxcA4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YITxqUDaZVa-"
      },
      "outputs": [],
      "source": [
        "def get_kth_layer_repr(input, k, device):\n",
        "  flattened_input = input.view((input.shape[0], -1)).type(torch.FloatTensor).to(device)\n",
        "  hidden_repr, __ = dbn_mnist.rbm_layers[k].to_hidden(flattened_input)  # here we access the RBM object\n",
        "  return hidden_repr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUv7HoQ3Dykm"
      },
      "outputs": [],
      "source": [
        "hidden_repr_layer_1 = get_kth_layer_repr(mnist_train.data, 0, device)\n",
        "hidden_repr_layer_2 = get_kth_layer_repr(hidden_repr_layer_1, 1, device)\n",
        "hidden_repr_layer_3 = get_kth_layer_repr(hidden_repr_layer_2, 2, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now compute the mean of https://www.displayr.com/what-is-hierarchical-clustering/"
      ],
      "metadata": {
        "id": "jxTQC1Ffez6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len((hidden_repr_layer_1).cpu().numpy()))\n",
        "\n",
        "x = range(0,len((hidden_repr_layer_1).cpu().numpy())) # 60000\n",
        "y = hidden_repr_layer_1.cpu().numpy() # idem\n",
        "\n",
        "# costruisco una matrice di associazioni (linkage), usando il Ward's linkage\n",
        "# che Ã¨ una versione \"macchina\" del dendrogramma\n",
        "data = list(zip(x, y))\n",
        "print(data);\n",
        "\n",
        "linkage_data = linkage(data, method='ward', metric='euclidean')\n",
        "\n",
        "#plt.show()\n",
        "#dendrogram(linkage_data)\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "d1TbHwrRhpVS",
        "outputId": "cc95fe01-e496-4f7b-9b50-9500fc72a27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/scipy/cluster/hierarchy.py:1046: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y = _convert_to_double(np.asarray(y, order='c'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-b1468675c6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlinkage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/cluster/hierarchy.py\u001b[0m in \u001b[0;36mlinkage\u001b[0;34m(y, method, metric, optimal_ordering)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid method: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/cluster/hierarchy.py\u001b[0m in \u001b[0;36m_convert_to_double\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igZyDYmrBkGK"
      },
      "outputs": [],
      "source": [
        "class LinearModel(torch.nn.Module):\n",
        "  def __init__(self, rbm_layer_size):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(rbm_layer_size, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z9mkfGCd5A9"
      },
      "outputs": [],
      "source": [
        "layer_size = dbn_mnist.rbm_layers[0].W.shape[1]\n",
        "linear_1 = LinearModel(layer_size).to(device)\n",
        "\n",
        "layer_size = dbn_mnist.rbm_layers[1].W.shape[1]\n",
        "linear_2 = LinearModel(layer_size).to(device)\n",
        "\n",
        "layer_size = dbn_mnist.rbm_layers[2].W.shape[1]\n",
        "linear_3 = LinearModel(layer_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ-6JyECcVdM"
      },
      "outputs": [],
      "source": [
        "def train(network, input, epochs=1000):\n",
        "  print_stride = 100 if epochs >= 1000 else 10\n",
        "  optimizer = torch.optim.SGD(network.parameters(), lr=0.05)\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  targets = mnist_train.targets\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = network(input)\n",
        "    loss = loss_fn(predictions, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % print_stride == 0:\n",
        "      print(\"epoch: {:4d}/{} | loss: {:.3f}\".format(epoch, epochs, loss))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck_DiqUEs3rq"
      },
      "outputs": [],
      "source": [
        "train(linear_1, hidden_repr_layer_1, epochs=1500)\n",
        "train(linear_2, hidden_repr_layer_2, epochs=1500)\n",
        "train(linear_3, hidden_repr_layer_3, epochs=1500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z7O7LWfCGsm"
      },
      "source": [
        "### Feedforward model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also build a common feedforward neural network to directly classify MNIST digits, to compare it with the DBN later."
      ],
      "metadata": {
        "id": "HG69ZzhOl_QO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vvpvET2CL3w"
      },
      "outputs": [],
      "source": [
        "class Feedforward(torch.nn.Module):\n",
        "  def __init__(self, first_hidden_layer_size, second_hidden_layer_size, third_hidden_layer_size):\n",
        "    super().__init__()\n",
        "    self.first_hidden = torch.nn.Linear(784, first_hidden_layer_size)\n",
        "    self.second_hidden = torch.nn.Linear(first_hidden_layer_size, second_hidden_layer_size)\n",
        "    self.third_hidden = torch.nn.Linear(second_hidden_layer_size, third_hidden_layer_size)\n",
        "    self.output = torch.nn.Linear(third_hidden_layer_size, 10)\n",
        "\n",
        "  def forward(self, input):\n",
        "    relu = torch.nn.ReLU()\n",
        "    first_hidden_repr = relu(self.first_hidden(input))\n",
        "    second_hidden_repr = relu(self.second_hidden(first_hidden_repr))\n",
        "    third_hidden_repr = relu(self.third_hidden(second_hidden_repr))\n",
        "    output = self.output(third_hidden_repr)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upl8aiD-gqP3"
      },
      "outputs": [],
      "source": [
        "ffnn = Feedforward(400, 500, 800).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccEZ2ZMFiBrX"
      },
      "outputs": [],
      "source": [
        "train(ffnn, mnist_train.data.reshape((60000, 784)), epochs=1500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SMR7wczaios"
      },
      "source": [
        "## Perturbing the models with adversarial attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV4JT4poGoCY"
      },
      "source": [
        "### Fast gradient sign method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mupwAJWJalgf"
      },
      "source": [
        "Reference: https://jaketae.github.io/study/fgsm/\n",
        "\n",
        "In general, with adversarial attacks we try to modify the input so that the model cannot correctly classify it anymore. This means that the loss for that specific input has to increase.\n",
        "\n",
        "The loss is usually a function of the input, the model's parameters and the outputs: $J(w, x, y)$.\n",
        "\n",
        "When we are training the model, we modify the model's weights based on the value of the gradient of the loss function, using the opposite direction w.r.t. the gradient because we want the loss to decrease. To create an adversarial sample we change two things in this procedure: \n",
        "1. we modify the input instead of the model's weights;\n",
        "2. we go in the same direction as the gradient, since we want the loss function to increase.\n",
        "\n",
        "The adversarial sample will then look like:\n",
        "\n",
        "$\\tilde{x} = x + \\epsilon \\cdot \\text{sign}(\\nabla_{x} J(w, x, y))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_Rw2ywr0cJd"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjnRDAHpchBD"
      },
      "source": [
        "### Adversarial samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNH21-AVKSPD"
      },
      "outputs": [],
      "source": [
        "class DBNWithReadOut(torch.nn.Module):\n",
        "    def __init__(self, dbn_mnist, readouts, readout_level=0):\n",
        "        super().__init__()\n",
        "        self.readouts = readouts\n",
        "        self.dbn_mnist = dbn_mnist\n",
        "        self._require_grad()\n",
        "        self.readout_level = readout_level\n",
        "\n",
        "    def _require_grad(self):\n",
        "      for rbm in self.dbn_mnist.rbm_layers:\n",
        "        rbm.W.requires_grad_()\n",
        "        rbm.h_bias.requires_grad_()\n",
        "\n",
        "    def forward(self, image):\n",
        "      \"\"\"This forward pass uses probabilities instead of samples as RBM outputs\n",
        "       to backpropagate the gradient\"\"\"\n",
        "      p_v = image\n",
        "      hidden_states = []\n",
        "      for rbm in self.dbn_mnist.rbm_layers:\n",
        "        p_v = p_v.view((p_v.shape[0], -1))  # flatten\n",
        "        p_v, v = rbm(p_v)\n",
        "        hidden_states.append(p_v)\n",
        "      return self.readouts[self.readout_level].forward(hidden_states[self.readout_level])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9ZeTZTzKywc"
      },
      "outputs": [],
      "source": [
        "dbn_with_readout = DBNWithReadOut(dbn_mnist, [linear_1, linear_2, linear_3], readout_level=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTcPTOhQxu5T"
      },
      "source": [
        "Let's see what an adversiarial sample looks like. Let't take one sample from the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OH3ZLHKx42A"
      },
      "outputs": [],
      "source": [
        "test_sample_idx = 1\n",
        "test_image = mnist_test.data[test_sample_idx].reshape(1, 784)\n",
        "__ = plt.imshow(test_image.reshape(28,28).to('cpu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYjBCsLwyBCu"
      },
      "source": [
        "Let's classify this \"clean\" image using one of the models we previously trained and then modify the image to attack the network.\n",
        "\n",
        "To change the model we attack, you can modify the value of the `model` variable in the cell below (choosing between `ffnn` and `dbn_with_readout`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TScIZSfJWPU5"
      },
      "outputs": [],
      "source": [
        "attacked_model = ffnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYOfVYmGedKJ"
      },
      "outputs": [],
      "source": [
        "attacked_model = dbn_with_readout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmChPDsCpU63"
      },
      "outputs": [],
      "source": [
        "test_image.requires_grad_()\n",
        "model_outputs = attacked_model(test_image)\n",
        "prediction = torch.argmax(model_outputs)\n",
        "print(f\"The prediction of the model for this clean sample is {prediction}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-Wjvo4ZydZS"
      },
      "source": [
        "Let's create and visualize the corresponding adversarial sample. \n",
        "The function `loss.backward()` computes the gradient for every parameter that was activated using the call `requires_grad=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM4T-mibycM4"
      },
      "outputs": [],
      "source": [
        "epsilon = 0.2  # define strenght of the attack\n",
        "test_image_label = mnist_test.targets[test_sample_idx].unsqueeze(0)  # get ground truth label for that image\n",
        "loss_value = torch.nn.functional.cross_entropy(model_outputs, test_image_label)  # get loss value\n",
        "attacked_model.zero_grad()\n",
        "loss_value.backward()\n",
        "image_grad = test_image.grad.data  # get the gradient of the pixels w.r.t. the loss\n",
        "perturbed_image = fgsm_attack(test_image, epsilon, image_grad)\n",
        "\n",
        "perturbed_image_np = perturbed_image.detach().to('cpu').numpy()\n",
        "__ = plt.imshow(perturbed_image_np.reshape(28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAAt6zmSynJw"
      },
      "outputs": [],
      "source": [
        "model_outputs = attacked_model(perturbed_image.view((perturbed_image.shape[0], -1)))\n",
        "print(f\"The prediction of the model for the perturbed sample is {torch.argmax(model_outputs)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5akVTqsck-l"
      },
      "source": [
        "### Resisting to adversarial attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rah2Uo4GJOuM"
      },
      "source": [
        "Let's now compare the ability to resist to adversarial attacks of our two models: the feedforward network and the DBN.\n",
        "\n",
        "We will also test the ability of the DBN to reduce the impact of the attack by performing one \"top-down\" reconstruction step, from the hidden representation of the last layer to the visible units, and back to the hidden representation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_robustness_to_attack(model, device, test_loader, epsilon, num_steps=0, verbose=True):\n",
        "    correct = 0\n",
        "    print_reconstruction = num_steps > 0\n",
        "\n",
        "    for data, target in tqdm(test_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        data = data.reshape(-1, 784)\n",
        "        data.requires_grad = True  # Important for Attack\n",
        "        \n",
        "        output = model.forward(data)\n",
        "\n",
        "        init_pred = torch.argmax(output)\n",
        "        \n",
        "        if (print_reconstruction and verbose):\n",
        "          print(\"\\nHere's the original sample:\\n\")\n",
        "          plt.imshow(data[0].detach().to('cpu').numpy().reshape(28,28))\n",
        "          plt.show()\n",
        "\n",
        "        loss = functional.nll_loss(output, target)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = data.grad.data  # collect the gradient of the input data\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        if (print_reconstruction and verbose):\n",
        "            print(\"\\nHere's a perturbed sample:\\n\")\n",
        "            plt.imshow(perturbed_data[0].detach().to('cpu').numpy().reshape(28,28))\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        # If requested, reconstruct the input iterating forward-backward dynamics\n",
        "        if num_steps > 0:\n",
        "            for __ in range(0, num_steps):\n",
        "                perturbed_data, __ = model.dbn_mnist.reconstruct(perturbed_data)\n",
        "            if (print_reconstruction and verbose):\n",
        "                print(f\"\\nHere's what a {num_steps}-steps reconstructed sample looks like:\\n\")\n",
        "                plt.imshow(perturbed_data[0].detach().to('cpu').numpy().reshape(28,28))\n",
        "                plt.show()\n",
        "                print_reconstruction = False\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        # get the index of the max element in the output\n",
        "        final_pred = output.max(1, keepdim=True)[1]\n",
        "        final_pred = output.argmax(-1)\n",
        "        correct += (final_pred == target).sum()\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader.sampler))\n",
        "    print(\"\\nEpsilon: {}\\nTest Accuracy: {:.2f}%\\n\".format(epsilon, final_acc*100))\n",
        "\n",
        "    return final_acc.item()"
      ],
      "metadata": {
        "id": "cWVue1BGTUj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-6DLRMjN92q"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    tv.datasets.MNIST('data/', train=False, download=False, transform=tv.transforms.Compose([tv.transforms.ToTensor()])),\n",
        "    batch_size=100, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7su_8C-9UWr"
      },
      "source": [
        "Let's see how good the FFNN does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84LAvrtbKAOi"
      },
      "outputs": [],
      "source": [
        "final_acc = test_robustness_to_attack(ffnn, device,\n",
        "                                      test_loader, epsilon=0.1,\n",
        "                                      num_steps=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KCv-ASM4UBK"
      },
      "source": [
        "Let's now compare compare with the read-out trained on the hidden representations of the DBN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3BEBuA1Im45"
      },
      "outputs": [],
      "source": [
        "final_acc = test_robustness_to_attack(dbn_with_readout, device,\n",
        "                                      test_loader, epsilon=0.1, \n",
        "                                      num_steps=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh4t-U6w9XzM"
      },
      "source": [
        "And finally let's test whether using one step of top-down reconstruction from the generative model allows to improve resilience to attacks:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_acc = test_robustness_to_attack(dbn_with_readout, device,\n",
        "                                      test_loader, epsilon=0.1,\n",
        "                                      num_steps=1)"
      ],
      "metadata": {
        "id": "Q6lGSQJ-MnYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCdXdcRUfbYT"
      },
      "source": [
        "### Effect of the noise parameter $\\epsilon$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDZ_O5L0JRUR"
      },
      "source": [
        "Let's compare the robustness of each model to adversarial attacks of different \"strengths\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CN2BNHv3iDc"
      },
      "outputs": [],
      "source": [
        "epsilon_values = [0, 0.05, 0.10, 0.15, 0.20, 0.25]\n",
        "\n",
        "def test_epsilon_values_effect(model, n_steps):\n",
        "  accuracies = list()\n",
        "\n",
        "  for eps in epsilon_values:\n",
        "      acc = test_robustness_to_attack(model, device, test_loader, eps, num_steps=n_steps, verbose=False)\n",
        "      accuracies.append(acc)\n",
        "\n",
        "  return accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_tuXYTg6Eeg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "accuracies_ffnn = test_epsilon_values_effect(ffnn, n_steps=0)\n",
        "accuracies_dbn_0 = test_epsilon_values_effect(dbn_with_readout, n_steps=0)\n",
        "accuracies_dbn_1 = test_epsilon_values_effect(dbn_with_readout, n_steps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtTPPywx4436"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(9, 7), sharey=True)\n",
        "\n",
        "__ = ax.axhline(0.1, color='gray', linestyle=':')\n",
        "__ = ax.plot(epsilon_values, accuracies_ffnn)\n",
        "__ = ax.plot(epsilon_values, accuracies_dbn_0)\n",
        "__ = ax.plot(epsilon_values, accuracies_dbn_1)\n",
        "__ = ax.set_xlabel(\"Strength of adversarial attack ($\\epsilon$)\")\n",
        "__ = ax.set_ylabel(\"Accuracy\")\n",
        "__ = ax.set_title(\"Robustness to adversarial attacks\", {'fontsize': 15})\n",
        "__ = ax.legend([\"Chance level\", \"FFNN\", \"DBN\", \"DBN top-down\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx8rFCR2afsT"
      },
      "source": [
        "## Contacts\n",
        "\n",
        "- ð§ flavio.petruzzellis@phd.unipd.it\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}